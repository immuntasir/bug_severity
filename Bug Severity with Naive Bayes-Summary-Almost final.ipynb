{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename to `file`\n",
    "file = 'Eclipse_4sourcev1.xls'\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "df = xl.parse('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  7373\n"
     ]
    }
   ],
   "source": [
    "print('Total: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifer:\n",
    "    def __init__(self):\n",
    "        self.name = 'Naive Bayes Classifier'\n",
    "    \n",
    "    def train (self, X_train, y_train, number_of_unique_words = 100000):\n",
    "        self.prior = np.zeros(5)\n",
    "        labels = list(y_train)\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.prior[i] = labels.count(i)/len(labels)\n",
    "        print(self.prior)\n",
    "        \n",
    "        self.mle_summary = np.zeros((number_of_unique_words, 5))\n",
    "        self.wordCount_summary = np.zeros(5)\n",
    "        self.uniqueWords_summary = np.zeros(5)\n",
    "        self.flag_summary = np.zeros(number_of_unique_words)\n",
    "        summaries = list(X_train.loc[:,'summary'])\n",
    "\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "        for summary in summaries:\n",
    "            self.dictionary.add_documents([summary.split()])\n",
    "\n",
    "        for i in range(len(summaries)):\n",
    "            summaries[i] = self.dictionary.doc2idx(summaries[i].split())\n",
    "        \n",
    "        for key in self.dictionary.keys():\n",
    "            for j in range(5):\n",
    "                self.mle_summary[key][labels[j]] = 1\n",
    "        \n",
    "        for i in range(len(summaries)):\n",
    "            summary = summaries[i]\n",
    "            for word in summary:\n",
    "                if (self.mle_summary[word][labels[i]] == 0):\n",
    "                    self.uniqueWords_summary[labels[i]] += 1\n",
    "                    self.mle_summary[word][labels[i]] = 0 \n",
    "                    self.flag_summary[word] += 1\n",
    "                \n",
    "                self.mle_summary[word][labels[i]] += 1 \n",
    "                self.wordCount_summary[labels[i]] += 1\n",
    "        \n",
    "        for i in range(number_of_unique_words):\n",
    "            for j in range(5):\n",
    "                self.mle_summary[i][j] += 1\n",
    "                self.mle_summary[i][j] /= (self.wordCount_summary[j] + self.uniqueWords_summary[j])\n",
    "        \n",
    "        self.mle_desc = np.zeros((number_of_unique_words, 5))\n",
    "        self.wordCount_desc = np.zeros(5)\n",
    "        \n",
    "        descriptions = list(X_train.loc[:,'description'])\n",
    "    \n",
    "        for description in descriptions:\n",
    "            self.dictionary.add_documents([description.split()])\n",
    "\n",
    "        for i in range(len(descriptions)):\n",
    "            descriptions[i] = self.dictionary.doc2idx(descriptions[i].split())\n",
    "        \n",
    "        \n",
    "        for i in range(len(descriptions)):\n",
    "            description = descriptions[i]\n",
    "            for word in description:\n",
    "                '''\n",
    "                if (i==0):\n",
    "                    print(word, self.wordCount_desc[word])\n",
    "                '''\n",
    "                self.mle_desc[word][labels[i]] += 1\n",
    "                self.wordCount_desc[labels[i]] += 1\n",
    "        \n",
    "        for i in range(number_of_unique_words):\n",
    "            for j in range(5):\n",
    "                self.mle_desc[i][j] += 1\n",
    "                self.mle_desc[i][j] /= self.wordCount_desc[labels[j]]\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def predict (self, X_test):\n",
    "        y_test = np.ones((X_test.shape[0], 5))\n",
    "        for i in range(X_test.shape[0]):\n",
    "            for j in range(5):\n",
    "                y_test[i][j] = (self.prior[j])\n",
    "        print(self.prior)\n",
    "        summaries = list(X_test.loc[:,'summary'])\n",
    "        for summary in summaries:\n",
    "            self.dictionary.add_documents([summary.split()])\n",
    "        for i in range(len(summaries)):\n",
    "            summaries[i] = self.dictionary.doc2idx(summaries[i].split())\n",
    "        \n",
    "        descriptions = list(X_test.loc[:,'description'])\n",
    "        for description in descriptions:\n",
    "            self.dictionary.add_documents([description.split()])\n",
    "        for i in range(len(descriptions)):\n",
    "            descriptions[i] = self.dictionary.doc2idx(descriptions[i].split())\n",
    "        \n",
    "        for i in range(X_test.shape[0]):\n",
    "            for j in range(5):\n",
    "                log_sum_summary = 0\n",
    "                log_sum_desc = 0\n",
    "                for word in summaries[i]:\n",
    "                    if word != -1 and self.mle_summary[word][j] != 0:\n",
    "                        log_sum_summary += np.log(self.mle_summary[word][j])\n",
    "                for word in descriptions[i]:\n",
    "                    if word != -1 and self.mle_desc[word][j] != 0:\n",
    "                        log_sum_desc += np.log(self.mle_desc[word][j])\n",
    "                \n",
    "                y_test[i][j] = np.log(y_test[i][j])\n",
    "                y_test[i][j] += ((log_sum_summary) )\n",
    "                \n",
    "                ''' + (log_sum_desc) '''\n",
    "        #print(y_test)\n",
    "        ret_val = np.zeros(len(y_test))\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(X_test.shape[0]):\n",
    "            mx = 0\n",
    "            mxindex = -1\n",
    "            for j in range(5):\n",
    "                if y_test[i][j] != 0:\n",
    "                    if mxindex == -1 or y_test[i][j] > mx:\n",
    "                        mxindex = j\n",
    "                        mx = y_test[i][j]\n",
    "            if mxindex == -1:\n",
    "                cnt += 1\n",
    "                mxindex = cnt % 5\n",
    "            ret_val[i] = mxindex\n",
    "        ret_val =  [int(round(x)) for x in ret_val] \n",
    "        print('Number of random classifications: ',cnt)\n",
    "        return list(ret_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create training and testing vars\n",
    "y = df.loc[:,'label'] - 1\n",
    "X = df.loc[:, 'summary':'component']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesClassifier = NaiveBayesClassifer()\n",
    "f1_scores_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04769001 0.3681073  0.33532042 0.17585693 0.07302534]\n",
      "[0.04769001 0.3681073  0.33532042 0.17585693 0.07302534]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "4712 698\n",
      "674 1191\n",
      "1160 2756\n",
      "9 1268\n",
      "147 789\n",
      "F-measure after  1 th iteration:  [0.20406654 0.18659517 0.22318693 0.00156617 0.10470085]\n",
      "[0.05070843 0.31618195 0.35868755 0.18866518 0.0857569 ]\n",
      "[0.05070843 0.31618195 0.35868755 0.18866518 0.0857569 ]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "2851 662\n",
      "1440 1014\n",
      "1247 2500\n",
      "88 1133\n",
      "406 723\n",
      "F-measure after  2 th iteration:  [0.22146314 0.22167889 0.26207633 0.08190008 0.21434898]\n",
      "[0.0512183  0.27747389 0.37493784 0.18896072 0.10740925]\n",
      "[0.0512183  0.27747389 0.37493784 0.18896072 0.10740925]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "2225 627\n",
      "1613 880\n",
      "1093 2227\n",
      "132 1006\n",
      "299 622\n",
      "F-measure after  3 th iteration:  [0.25806452 0.21259527 0.27228916 0.13884007 0.28230185]\n",
      "[0.05033557 0.24794929 0.39932886 0.19686801 0.10551827]\n",
      "[0.05033557 0.24794929 0.39932886 0.19686801 0.10551827]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "1837 595\n",
      "1633 773\n",
      "830 1910\n",
      "118 858\n",
      "273 555\n",
      "F-measure after  4 th iteration:  [0.26973684 0.22776392 0.24379562 0.1454918  0.30193237]\n",
      "[0.0528043  0.23687351 0.40662291 0.19570406 0.10799523]\n",
      "[0.0528043  0.23687351 0.40662291 0.19570406 0.10799523]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "1287 553\n",
      "1692 644\n",
      "663 1618\n",
      "129 730\n",
      "250 476\n",
      "F-measure after  5 th iteration:  [0.26956522 0.25171233 0.24462955 0.16996508 0.3030303 ]\n",
      "[0.05768274 0.22501243 0.41074092 0.20014918 0.10641472]\n",
      "[0.05768274 0.22501243 0.41074092 0.20014918 0.10641472]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "882 498\n",
      "1497 533\n",
      "614 1329\n",
      "136 581\n",
      "222 410\n",
      "F-measure after  6 th iteration:  [0.27391304 0.25123153 0.2624807  0.17852162 0.32278481]\n",
      "[0.05839727 0.2173913  0.4102728  0.20034101 0.11359761]\n",
      "[0.05839727 0.2173913  0.4102728  0.20034101 0.11359761]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "642 456\n",
      "1235 418\n",
      "494 1056\n",
      "128 446\n",
      "182 305\n",
      "F-measure after  7 th iteration:  [0.27686703 0.25408348 0.25677419 0.21602787 0.32854209]\n",
      "[0.07327988 0.20846541 0.40257319 0.19914227 0.11653925]\n",
      "[0.07327988 0.20846541 0.40257319 0.19914227 0.11653925]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "446 337\n",
      "1009 320\n",
      "345 822\n",
      "88 318\n",
      "122 213\n",
      "F-measure after  8 th iteration:  [0.26819923 0.23927765 0.25535561 0.20197044 0.32238806]\n",
      "[0.07541853 0.20039781 0.40261893 0.20023206 0.12133267]\n",
      "[0.07541853 0.20039781 0.40261893 0.20023206 0.12133267]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "301 275\n",
      "711 229\n",
      "219 552\n",
      "48 178\n",
      "61 106\n",
      "F-measure after  9 th iteration:  [0.28819444 0.26170213 0.26459144 0.17699115 0.31137725]\n",
      "[0.08294793 0.19528569 0.40563927 0.19558407 0.12054304]\n",
      "[0.08294793 0.19528569 0.40563927 0.19558407 0.12054304]\n",
      "Number of random classifications:  0\n",
      "Count: Train vs Test\n",
      "149 174\n",
      "340 129\n",
      "129 262\n",
      "23 75\n",
      "29 30\n",
      "F-measure after  10 th iteration:  [0.28482972 0.30277186 0.31202046 0.20408163 0.23728814]\n"
     ]
    }
   ],
   "source": [
    "f1_scores = np.zeros((10, 5))\n",
    "for i in range(1,11):\n",
    "    split_point = (len(X)/11) * i\n",
    "    naiveBayesClassifier.train(X_train = X.loc[0:split_point,], y_train = y.loc[0:split_point, ])\n",
    "    y_test = naiveBayesClassifier.predict(X_test = X.loc[split_point:, ])\n",
    "    \n",
    "    \n",
    "    y_label = list(y.loc[split_point:, ])\n",
    "    \n",
    "    #print(y_test, y_label)\n",
    "    #print((y_test == y_label).count(True) / len(y_test))\n",
    "    \n",
    "    \n",
    "    true_positive = np.zeros(5)\n",
    "    \n",
    "    false_positive = np.zeros(5)\n",
    "    false_negative = np.zeros(5)\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        if (y_test[j] == y_label[j]):\n",
    "            true_positive[y_test[j]] += 1\n",
    "        else:\n",
    "            false_positive[y_test[j]] += 1\n",
    "            false_negative[y_label[j]] += 1\n",
    "    \n",
    "    precision = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "    for j in range(5):\n",
    "        precision[j] = true_positive[j] / (true_positive[j] + false_positive[j])\n",
    "        recall[j] = true_positive[j] / (true_positive[j] + false_negative[j])\n",
    "    \n",
    "    for j in range(5):\n",
    "        f1_scores[i-1][j] = (2 * (precision[j] * recall[j])) / (precision[j] + recall[j]) \n",
    "    print('Count: Train vs Test')\n",
    "    print(y_test.count(0), y_label.count(0))\n",
    "    print(y_test.count(1), y_label.count(1))\n",
    "    print(y_test.count(2), y_label.count(2))\n",
    "    print(y_test.count(3), y_label.count(3))\n",
    "    print(y_test.count(4), y_label.count(4))\n",
    "    \n",
    "    print('F-measure after ', i, 'th iteration: ', f1_scores[i-1])\n",
    "    f1_scores_list.append(f1_scores)\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26148997, 0.24094122, 0.25972   , 0.15153559, 0.27286947])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(f1_scores_list[0]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 = [0.29708908, 0.12242544, 0.12195517, 0.23450966, 0.30316858]\n",
    "# v2 = [0.2995275 , 0.1467392 , 0.19238292, 0.25886584, 0.30322861]\n",
    "# v3 = [0.29927012, 0.19800515, 0.22370673, 0.23961686, 0.29768361]\n",
    "# v4 = [0.42516269 0.26804124 0.35078534 0.3        0.20930233]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
