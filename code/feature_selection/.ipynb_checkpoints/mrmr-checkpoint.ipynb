{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pymrmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename to `file`\n",
    "file = '../../data/Eclipse_4sourcev1.xls'\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "df = xl.parse('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  7373\n"
     ]
    }
   ],
   "source": [
    "print('Total: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifer:\n",
    "    def __init__(self):\n",
    "        self.name = 'Naive Bayes Classifier'\n",
    "    \n",
    "    def train (self, X_train, y_train, number_of_unique_words = 100000):\n",
    "        self.prior = np.zeros(5)\n",
    "        labels = list(y_train)\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.prior[i] = labels.count(i)/len(labels)\n",
    "        \n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "        summaries = list(X_train.loc[:,'summary'])\n",
    "        for summary in summaries:\n",
    "            self.dictionary.add_documents([summary.split()])\n",
    "        \n",
    "        self.number_of_unique_words = len(self.dictionary)\n",
    "        print('Number of unique words:', self.number_of_unique_words)\n",
    "        self.summary_feature = np.ones((len(X_train), self.number_of_unique_words))\n",
    "        self.summary_word_count = np.ones((5, self.number_of_unique_words))\n",
    "        \n",
    "        for i in range(len(summaries)):\n",
    "            summaries[i] = self.dictionary.doc2idx(summaries[i].split())\n",
    "        \n",
    "        for i in range(len(summaries)):\n",
    "            for j in range(len(summaries[i])):\n",
    "                self.summary_feature[i][summaries[i][j]] += 1\n",
    "                self.summary_word_count[labels[i]][summaries[i][j]] += 1\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.summary_word_count[i] /= np.sum(self.summary_word_count[i]) \n",
    "        \n",
    "        dictionary = {}\n",
    "        for itr in range(self.summary_feature.shape[1]):\n",
    "            dictionary[str(itr)] = self.summary_feature[:, itr]\n",
    "        self.dataframe = pd.DataFrame.from_dict(dictionary)\n",
    "        del dictionary\n",
    "        \n",
    "        self.important_features = pymrmr.mRMR(self.dataframe, 'MIQ', 50)\n",
    "        \n",
    "        print('Total number of features:', self.number_of_unique_words)\n",
    "        print('Number of selected features:', len(self.important_features))\n",
    "        \n",
    "    def predict (self, X_test):\n",
    "        y_test = np.ones((X_test.shape[0], 5))\n",
    "        \n",
    "        '''\n",
    "        for i in range(X_test.shape[0]):\n",
    "            for j in range(5):\n",
    "                y_test[i][j] = (self.prior[j])\n",
    "        '''\n",
    "        \n",
    "        summaries = list(X_test.loc[:,'summary'])\n",
    "        \n",
    "        for i in range(len(summaries)):\n",
    "            summaries[i] = self.dictionary.doc2idx(summaries[i].split())\n",
    "        \n",
    "        for i in range(X_test.shape[0]):\n",
    "            for lab in range(5):\n",
    "                log_sum_summary = 0\n",
    "                for j in range(len(summaries[i])):\n",
    "                    if (summaries[i][j] != -1 and summaries[i][j] in self.important_features and self.summary_word_count[lab][summaries[i][j]]):\n",
    "                        log_sum_summary += np.log(self.summary_word_count[lab][summaries[i][j]])\n",
    "        \n",
    "                #y_test[i][lab] = np.log(y_test[i][lab])\n",
    "                y_test[i][lab] += ((log_sum_summary))\n",
    "                \n",
    "        \n",
    "        for i in range(X_test.shape[0]):\n",
    "            y_test[i] /= (np.sum(y_test[i]) - y_test[i])\n",
    "            y_test[i] = -y_test[i]\n",
    "            \n",
    "        ret_val = np.zeros(len(y_test))\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(X_test.shape[0]):\n",
    "            mx = 0\n",
    "            mxindex = -1\n",
    "            for j in range(5):\n",
    "                if y_test[i][j] != 0:\n",
    "                    if mxindex == -1 or y_test[i][j] > mx:\n",
    "                        mxindex = j\n",
    "                        mx = y_test[i][j]\n",
    "            if mxindex == -1:\n",
    "                cnt += 1\n",
    "                mxindex = cnt % 5\n",
    "            ret_val[i] = mxindex\n",
    "        ret_val =  [int(round(x)) for x in ret_val] \n",
    "        print('Number of random classifications: ',cnt)\n",
    "        return list(ret_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create training and testing vars\n",
    "y = df.loc[:,'label'] - 1\n",
    "X = df.loc[:, 'summary':'component']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesClassifier = NaiveBayesClassifer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 1064\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f047238f2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1b9800cd8a63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, number_of_unique_words)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportant_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymrmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmRMR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MIQ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total number of features:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_unique_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pymrmr/pymrmr.pyx\u001b[0m in \u001b[0;36mpymrmr.mRMR (pymrmr/pymrmr.cpp:1804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index does not support mutable operations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m         \"\"\"\n\u001b[1;32m   2069\u001b[0m         \u001b[0mOverride\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0m__getitem__\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwork\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_scores = np.zeros((10, 5))\n",
    "f1_scores_list = []\n",
    "for i in range(1,11):\n",
    "    split_point = (len(X)/11) * i\n",
    "    naiveBayesClassifier.train(X_train = X.loc[0:split_point,], y_train = y.loc[0:split_point, ])\n",
    "    y_test = naiveBayesClassifier.predict(X_test = X.loc[split_point:, ])\n",
    "    \n",
    "    \n",
    "    y_label = list(y.loc[split_point:, ])\n",
    "    \n",
    "    #print(y_test, y_label)\n",
    "    #print((y_test == y_label).count(True) / len(y_test))\n",
    "    \n",
    "    \n",
    "    true_positive = np.zeros(5)\n",
    "    \n",
    "    false_positive = np.zeros(5)\n",
    "    false_negative = np.zeros(5)\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        if (y_test[j] == y_label[j]):\n",
    "            true_positive[y_test[j]] += 1\n",
    "        else:\n",
    "            false_positive[y_test[j]] += 1\n",
    "            false_negative[y_label[j]] += 1\n",
    "    \n",
    "    precision = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "    for j in range(5):\n",
    "        precision[j] = true_positive[j] / (true_positive[j] + false_positive[j])\n",
    "        recall[j] = true_positive[j] / (true_positive[j] + false_negative[j])\n",
    "    \n",
    "    for j in range(5):\n",
    "        f1_scores[i-1][j] = (2 * (precision[j] * recall[j])) / (precision[j] + recall[j])\n",
    "        if np.isnan(f1_scores[i-1][j]):\n",
    "            f1_scores[i-1][j] = 0\n",
    "    print('Count: Train vs Test')\n",
    "    print(y_test.count(0), y_label.count(0))\n",
    "    print(y_test.count(1), y_label.count(1))\n",
    "    print(y_test.count(2), y_label.count(2))\n",
    "    print(y_test.count(3), y_label.count(3))\n",
    "    print(y_test.count(4), y_label.count(4))\n",
    "    \n",
    "    print('F-measure after ', i, 'th iteration: ', f1_scores[i-1])\n",
    "    f1_scores_list.append(f1_scores)\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(f1_scores_list[0]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round robin classification:           [0.16300248, 0.17159368, 0.26298052, 0.1744121 , 0.12709789]\n",
    "# without prior without smoothing:      [0.21465332, 0.10047268, 0.05816234, 0.08378671, 0.09948181]\n",
    "# with prior without smoothing:         [0.17769152, 0.12833085, 0.14291655, 0.10463765, 0.0911579 ]\n",
    "# without prior with smoothing:         [0.21558835, 0.23368606, 0.42980058, 0.31752347, 0.2647105 ]\n",
    "# with prior with smoothing:            [0.0466586 , 0.21333919, 0.50649528, 0.30572038, 0.20783305]\n",
    "# with likelihood ratio with smoothing: [0.21558835, 0.23368606, 0.42980058, 0.31752347, 0.2647105 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
